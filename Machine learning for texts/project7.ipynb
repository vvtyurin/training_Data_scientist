{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загружаем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, train_test_split\n",
    "from sklearn import linear_model\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor \n",
    "from sklearn.metrics import f1_score\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загружаем файл и смотрим его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic = pd.read_csv('c:\\\\123\\\\toxic_comments.csv')\n",
    "toxic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "смотрим информацию по файлу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "toxic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "видим разбивку, по нет понимания, надо ли уравновешивать классы? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = toxic['text'] # создадим корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "# разбиваем текст на слова и избавляемся от пробелов\n",
    "def lemmatize(text):\n",
    "    words = text.split() \n",
    "    res = list()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "\n",
    "    return \" \".join(res)\n",
    "\n",
    "def clear_text(text):\n",
    "    cyrillic_text = re.sub(r'[^a-zA-Z]', \" \", text)\n",
    "    \n",
    "    return \" \".join(cyrillic_text.split())\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explanation why the edits made under my userna...\n",
       "1    d aww he matches this background colour i m se...\n",
       "2    hey man i m really not trying to edit war it s...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_text = corpus.apply(lambda x: lemmatize(clear_text(x)) )\n",
    "lemmatized_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создаем выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lemmatized_text, toxic['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создадим два мешка слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train'a: (119678, 142497)\n",
      "Размер test'a: (39893, 142497)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words=stopwords)\n",
    "n_gramm_train = count_vect.fit_transform(X_train)\n",
    "n_gramm_test = count_vect.transform(X_test)\n",
    "\n",
    "print(\"Размер train'a:\", n_gramm_train.shape)\n",
    "print(\"Размер test'a:\", n_gramm_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train'a: (119678, 2271968)\n",
      "Размер test'a: (39893, 2271968)\n"
     ]
    }
   ],
   "source": [
    "Tf_Idf_count = TfidfVectorizer(stop_words=stopwords, ngram_range=(1, 2))\n",
    "n_gramm_train_tf = Tf_Idf_count.fit_transform(X_train)\n",
    "n_gramm_test_tf = Tf_Idf_count.transform(X_test)\n",
    "\n",
    "print(\"Размер train'a:\", n_gramm_train_tf.shape)\n",
    "print(\"Размер test'a:\", n_gramm_test_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучаем разнные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9751750530590417\n",
      "test: 0.9473341187677036\n",
      "\n",
      "F1: 0.7611685801977947\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=12345, class_weight='balanced')\n",
    "lr.fit(n_gramm_train, y_train)\n",
    "print(\"train:\", lr.score(n_gramm_train, y_train))\n",
    "print(\"test:\", lr.score(n_gramm_test, y_test))\n",
    "f1_lr = f1_score(y_test, lr.predict(n_gramm_test))\n",
    "print(\"\\nF1:\", f1_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9797874296027674\n",
      "test: 0.9432983230140626\n",
      "\n",
      "F1: 0.747375474648202\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=12345, class_weight='balanced')\n",
    "lr.fit(n_gramm_train_tf, y_train)\n",
    "print(\"train:\", lr.score(n_gramm_train_tf, y_train))\n",
    "print(\"test:\", lr.score(n_gramm_test_tf, y_test))\n",
    "f1_lr_tf = f1_score(y_test, lr.predict(n_gramm_test_tf))\n",
    "print(\"\\nF1:\", f1_lr_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9997409716071458\n",
      "test: 0.9459052966685885\n",
      "\n",
      "F1: 0.6479608482871126\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=12345, class_weight='balanced')\n",
    "rfc.fit(n_gramm_train, y_train)\n",
    "print(\"train:\", rfc.score(n_gramm_train, y_train))\n",
    "print(\"test:\", rfc.score(n_gramm_test, y_test))\n",
    "f1_rfc = f1_score(y_test, rfc.predict(n_gramm_test))\n",
    "print(\"\\nF1:\", f1_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.999749327361754\n",
      "test: 0.9376582357807134\n",
      "\n",
      "F1: 0.5586512866015971\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=12345, class_weight='balanced')\n",
    "rfc.fit(n_gramm_train_tf, y_train)\n",
    "print(\"train:\", rfc.score(n_gramm_train_tf, y_train))\n",
    "print(\"test:\", rfc.score(n_gramm_test_tf, y_test))\n",
    "f1_rfc_tf = f1_score(y_test, rfc.predict(n_gramm_test_tf))\n",
    "print(\"\\nF1:\", f1_rfc_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = []\n",
    "mod_lr = [f1_lr, f1_lr_tf]\n",
    "mod_rfc = [f1_rfc, f1_rfc_tf]\n",
    "model.append(mod_lr)\n",
    "model.append(mod_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = pd.DataFrame(data=model, index=['LogisticRegression', 'RandomForestClassifier'], columns=['CountVectorizer', 'TfidfVectorizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountVectorizer</th>\n",
       "      <th>TfidfVectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.761169</td>\n",
       "      <td>0.747375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.647961</td>\n",
       "      <td>0.558651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        CountVectorizer  TfidfVectorizer\n",
       "LogisticRegression             0.761169         0.747375\n",
       "RandomForestClassifier         0.647961         0.558651"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "наивысшая метрика f1 достигнута при применении класса CountVectorizer, на модели LogisticRegression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
